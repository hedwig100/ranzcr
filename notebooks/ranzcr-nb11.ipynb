{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-03-16T08:36:43.362255Z",
     "iopub.status.busy": "2021-03-16T08:36:43.361612Z",
     "iopub.status.idle": "2021-03-16T08:36:51.157228Z",
     "shell.execute_reply": "2021-03-16T08:36:51.156001Z"
    },
    "papermill": {
     "duration": 7.812154,
     "end_time": "2021-03-16T08:36:51.157446",
     "exception": false,
     "start_time": "2021-03-16T08:36:43.345292",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os,gc\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from functools import partial\n",
    "import albumentations as albu\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from kaggle_datasets import KaggleDatasets \n",
    "from sklearn.model_selection import train_test_split \n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow.keras.applications.efficientnet as efn \n",
    "from tensorflow.keras.applications import ResNet152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-16T08:36:51.183121Z",
     "iopub.status.busy": "2021-03-16T08:36:51.182503Z",
     "iopub.status.idle": "2021-03-16T08:36:51.192704Z",
     "shell.execute_reply": "2021-03-16T08:36:51.192009Z"
    },
    "papermill": {
     "duration": 0.02602,
     "end_time": "2021-03-16T08:36:51.192883",
     "exception": false,
     "start_time": "2021-03-16T08:36:51.166863",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on 1 replicas\n"
     ]
    }
   ],
   "source": [
    "def auto_select_accelerator():\n",
    "    tpu_ok = False \n",
    "    try:\n",
    "        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "        tf.config.experimental_connect_to_cluster(tpu)\n",
    "        tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "        strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "        tpu_ok = True\n",
    "        print(\"Running on TPU:\", tpu.master())\n",
    "    except ValueError:\n",
    "        strategy = tf.distribute.get_strategy()\n",
    "    print(f\"Running on {strategy.num_replicas_in_sync} replicas\")\n",
    "    return strategy,tpu_ok\n",
    "\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "strategy,tpu_ok = auto_select_accelerator()\n",
    "if tpu_ok:\n",
    "    load_dir = KaggleDatasets().get_gcs_path(\"ranzcr-clip-catheter-line-classification\")\n",
    "else:\n",
    "    load_dir = \"../input/ranzcr-clip-catheter-line-classification\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-16T08:36:51.219117Z",
     "iopub.status.busy": "2021-03-16T08:36:51.218401Z",
     "iopub.status.idle": "2021-03-16T08:36:51.221916Z",
     "shell.execute_reply": "2021-03-16T08:36:51.221465Z"
    },
    "papermill": {
     "duration": 0.01867,
     "end_time": "2021-03-16T08:36:51.222053",
     "exception": false,
     "start_time": "2021-03-16T08:36:51.203383",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCHS : 40\n",
      "BATCHSIZE : 16\n"
     ]
    }
   ],
   "source": [
    "labels = np.array(['ETT - Abnormal', 'ETT - Borderline',\n",
    "       'ETT - Normal', 'NGT - Abnormal', 'NGT - Borderline',\n",
    "       'NGT - Incompletely Imaged', 'NGT - Normal', 'CVC - Abnormal',\n",
    "       'CVC - Borderline', 'CVC - Normal', 'Swan Ganz Catheter Present'])\n",
    "\n",
    "DEBUG = False \n",
    "class CONFIG:\n",
    "    version = 4 \n",
    "    batchsize =16*strategy.num_replicas_in_sync\n",
    "    epochs = 1 if DEBUG else 40    \n",
    "    imsize = (512,512) \n",
    "    shuffle = 2048\n",
    "    seed = 123 \n",
    "    lr = 1e-3 \n",
    "    min_lr = 5e-6\n",
    "    max_lr = 1e-3\n",
    "    n_labels = 11 \n",
    "    n_folds = 5\n",
    "    tta = 2\n",
    "\n",
    "print(f\"EPOCHS : {CONFIG.epochs}\")\n",
    "print(f\"BATCHSIZE : {CONFIG.batchsize}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-16T08:36:51.264471Z",
     "iopub.status.busy": "2021-03-16T08:36:51.263765Z",
     "iopub.status.idle": "2021-03-16T08:36:51.266507Z",
     "shell.execute_reply": "2021-03-16T08:36:51.266993Z"
    },
    "papermill": {
     "duration": 0.035639,
     "end_time": "2021-03-16T08:36:51.267170",
     "exception": false,
     "start_time": "2021-03-16T08:36:51.231531",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Utils \n",
    "def seed_everything(seed):\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    \n",
    "## decoder \n",
    "def decoder_image(img):\n",
    "    img = tf.io.decode_jpeg(img,channels=3)\n",
    "    img = tf.cast(img,tf.float32) #float32„Å´cast\n",
    "    img /= 255.0 \n",
    "    img = tf.image.resize(img,CONFIG.imsize)\n",
    "    return img\n",
    "\n",
    "\n",
    "## Augmentation\n",
    "def augmenter(img,label):\n",
    "    img = tf.image.random_flip_left_right(img)\n",
    "    img = tf.image.random_flip_up_down(img)\n",
    "    img = tf.image.random_hue(img,max_delta=0.01)\n",
    "    img = tf.image.random_saturation(img,lower=0.70,upper=1.30) #factor\n",
    "    img = tf.image.random_contrast(img,lower=0.80,upper=1.20) #factor\n",
    "    img = tf.image.random_brightness(img,max_delta=0.10)\n",
    "    return img,label\n",
    "\n",
    "## For TFRecord \n",
    "def read_labeled_tfrecord(example):\n",
    "    LABELED_TFREC_FORMAT = {\n",
    "        \"image\" : tf.io.FixedLenFeature([],tf.string),\n",
    "        \"ETT - Abnormal\":tf.io.FixedLenFeature([],tf.int64),\n",
    "        \"ETT - Borderline\":tf.io.FixedLenFeature([],tf.int64),\n",
    "        \"ETT - Normal\":tf.io.FixedLenFeature([],tf.int64),\n",
    "        \"NGT - Abnormal\":tf.io.FixedLenFeature([],tf.int64),\n",
    "        \"NGT - Borderline\":tf.io.FixedLenFeature([],tf.int64),\n",
    "        \"NGT - Incompletely Imaged\":tf.io.FixedLenFeature([],tf.int64),\n",
    "        \"NGT - Normal\":tf.io.FixedLenFeature([],tf.int64),\n",
    "        \"CVC - Abnormal\":tf.io.FixedLenFeature([],tf.int64),\n",
    "        \"CVC - Borderline\":tf.io.FixedLenFeature([],tf.int64),\n",
    "        \"CVC - Normal\":tf.io.FixedLenFeature([],tf.int64),\n",
    "        \"Swan Ganz Catheter Present\":tf.io.FixedLenFeature([],tf.int64),\n",
    "        'StudyInstanceUID': tf.io.FixedLenFeature([],tf.string),\n",
    "        'PatientID':tf.io.FixedLenFeature([],tf.string) \n",
    "    }\n",
    "    example = tf.io.parse_single_example(example,LABELED_TFREC_FORMAT)\n",
    "    image = decoder_image(example[\"image\"])\n",
    "    targets = tf.stack([tf.cast(example[label],tf.float32) for label in labels])\n",
    "    return image,targets\n",
    "\n",
    "def make_dataset(paths,cache_dir=False,augment=False,repeat=False,shuffle=0):\n",
    "    if cache_dir:\n",
    "        os.makedirs(cache_dir,exist_ok=True)\n",
    "    dset = tf.data.TFRecordDataset(paths)\n",
    "    dset = dset.map(read_labeled_tfrecord,num_parallel_calls=AUTO)\n",
    "    dset = dset.cache(cache_dir) if cache_dir else dset \n",
    "    dset = dset.map(augmenter,num_parallel_calls=AUTO) if augment else dset\n",
    "    dset = dset.repeat() if repeat else dset\n",
    "    dset = dset.shuffle(shuffle) if shuffle else dset \n",
    "    dset = dset.batch(CONFIG.batchsize)\n",
    "    dset = dset.prefetch(AUTO)\n",
    "    return dset\n",
    "\n",
    "def change_shape(img_label,teacher):\n",
    "    img = img_label[0]\n",
    "    label = img_label[1]\n",
    "    return img,tf.concat((label,teacher),axis=0)\n",
    "\n",
    "def make_teacher_dataset(paths,teacher_pred,cache_dir=False,augment=False,repeat=False,shuffle=0):\n",
    "    dset = tf.data.TFRecordDataset(paths)\n",
    "    teacher = tf.data.Dataset.from_tensor_slices(teacher_pred)\n",
    "    dset = dset.map(read_labeled_tfrecord,num_parallel_calls=AUTO)\n",
    "    dset = tf.data.Dataset.zip((dset,teacher))\n",
    "    dset = dset.map(change_shape,num_parallel_calls=AUTO)\n",
    "    \n",
    "    dset = dset.map(augmenter,num_parallel_calls=AUTO) if augment else dset \n",
    "    dset = dset.repeat() if repeat else dset\n",
    "    dset = dset.shuffle(shuffle) if shuffle else dset \n",
    "    dset = dset.batch(CONFIG.batchsize)\n",
    "    dset = dset.prefetch(AUTO)\n",
    "    return dset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-16T08:36:51.315228Z",
     "iopub.status.busy": "2021-03-16T08:36:51.312220Z",
     "iopub.status.idle": "2021-03-16T08:36:51.328043Z",
     "shell.execute_reply": "2021-03-16T08:36:51.326992Z"
    },
    "papermill": {
     "duration": 0.051544,
     "end_time": "2021-03-16T08:36:51.328212",
     "exception": false,
     "start_time": "2021-03-16T08:36:51.276668",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "## Custom Loss\n",
    "pos_weight = tf.constant([0.99737393,0.96217133,0.75933251,0.99072566,0.98241532,\n",
    "              0.90865273,0.84054117,0.89379384,0.71877805,0.29116112,\n",
    "              0.97240967],tf.float32)\n",
    "neg_weight = tf.constant([0.00262607,0.03782867,0.24066749,0.00927434,0.01758468,\n",
    "              0.09134727,0.15945883,0.10620616,0.28122195,0.70883888,\n",
    "              0.02759033],tf.float32)\n",
    "mul = tf.multiply\n",
    "def WeightedBinaryCrossentropy(y_true,y_pred):\n",
    "    y_true = tf.cast(y_true,tf.float32)\n",
    "    pos_loss = -mul(mul(      y_true,tf.math.log(    y_pred + 1e-13)),pos_weight) \n",
    "    neg_loss = -mul(mul(1.0 - y_true,tf.math.log(1.0 - y_pred + 1e-13)),neg_weight) \n",
    "    loss = tf.add(pos_loss,neg_loss)\n",
    "    return tf.math.reduce_mean(loss,0)\n",
    "\n",
    "def CustomLoss(y_true,y_pred):\n",
    "    student_feature = y_pred[:,:11]\n",
    "    student_prob = y_pred[:,11:]\n",
    "    teacher_feature = y_true[:,11:]\n",
    "    teacher_prob = y_true[:,:11] \n",
    "    \n",
    "    # BCE \n",
    "    pos_loss = -mul(mul(      teacher_prob,tf.math.log(      student_prob + 1e-13)),pos_weight) \n",
    "    neg_loss = -mul(mul(1.0 - teacher_prob,tf.math.log(1.0 - student_prob + 1e-13)),neg_weight) \n",
    "    loss = tf.add(pos_loss,neg_loss)\n",
    "    bce = tf.math.reduce_mean(loss,0)\n",
    "    \n",
    "    # L2 \n",
    "    mse = tf.math.square(teacher_feature - student_feature)\n",
    "    mse = tf.math.reduce_mean(mse,0)\n",
    "    \n",
    "    total_loss = tf.math.reduce_mean(bce + mse/2,0) \n",
    "    return total_loss\n",
    "\n",
    "\n",
    "## Metrics\n",
    "def mean_roc_auc(targets,probabilities):\n",
    "    roc_auc = [roc_auc_score(targets[:,k],probabilities[:,k]) for k in range(CONFIG.n_labels)]\n",
    "    return np.average(roc_auc)\n",
    "\n",
    "metric_fn = tf.keras.metrics.AUC(multi_label=True)\n",
    "def mean_roc_auc_(y_true,y_pred):\n",
    "    y_pred = y_pred[:,11:] \n",
    "    y_true = y_true[:,:11]\n",
    "    metric_fn.update_state(y_true,y_pred)\n",
    "    return metric_fn.result()\n",
    "\n",
    "## Annealing \n",
    "def CosineAnnealing(epoch,lr):\n",
    "    return CONFIG.min_lr + (CONFIG.max_lr - CONFIG.min_lr)*(1 + np.cos(epoch/CONFIG.epochs*np.pi))/2 \n",
    "\n",
    "\n",
    "## Model \n",
    "def create_teacher_model():\n",
    "    with strategy.scope():\n",
    "        model = tf.keras.Sequential([\n",
    "            ResNet152(input_shape=(*CONFIG.imsize,3),\n",
    "                                  weights=None, \n",
    "                                  include_top=False),\n",
    "            tf.keras.layers.GlobalAveragePooling2D(),\n",
    "            tf.keras.layers.Dense(CONFIG.n_labels)\n",
    "        ])\n",
    "    return model\n",
    "    \n",
    "def create_model():\n",
    "    with strategy.scope():\n",
    "        inp = tf.keras.layers.Input(shape=(*CONFIG.imsize,3))\n",
    "        x = ResNet152(weights=\"imagenet\",include_top=False)(inp)\n",
    "        x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "        x = tf.keras.layers.Dense(CONFIG.n_labels)(x) \n",
    "        y = tf.keras.layers.Activation(\"sigmoid\")(x) \n",
    "        out = tf.keras.layers.Concatenate(axis = 1)([x,y])\n",
    "        model = tf.keras.models.Model(inputs = inp,outputs = out) \n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=CONFIG.lr),\n",
    "                      loss=CustomLoss,\n",
    "                      metrics=mean_roc_auc_) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-16T08:36:51.351138Z",
     "iopub.status.busy": "2021-03-16T08:36:51.350155Z",
     "iopub.status.idle": "2021-03-16T08:36:51.370115Z",
     "shell.execute_reply": "2021-03-16T08:36:51.369650Z"
    },
    "papermill": {
     "duration": 0.032289,
     "end_time": "2021-03-16T08:36:51.370264",
     "exception": false,
     "start_time": "2021-03-16T08:36:51.337975",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cv_tuner_from_tf(annot_path,path,df,n_folds=CONFIG.n_folds):\n",
    "    scores = []\n",
    "    seed_everything(CONFIG.seed)\n",
    "    ANNOT_GCS_PATH = KaggleDatasets().get_gcs_path(annot_path) \n",
    "    GCS_PATH = KaggleDatasets().get_gcs_path(path) \n",
    "    for fold in range(n_folds):\n",
    "        print(\"-\"*50)\n",
    "        if fold == 1: #5fold is time consuming \n",
    "            break \n",
    "        annot_train_paths = [ANNOT_GCS_PATH + f\"/train_annot_{CONFIG.imsize[0]}_{i}.tfrec\" for i in range(n_folds) if i != fold]\n",
    "        annot_valid_path = ANNOT_GCS_PATH + f\"/train_annot_{CONFIG.imsize[0]}_{fold}.tfrec\"\n",
    "        train_paths = [GCS_PATH + f\"/train_withoutannot_clahe_{CONFIG.imsize[0]}_{i}.tfrec\" for i in range(n_folds) if i != fold]\n",
    "        valid_path = GCS_PATH + f\"/train_withoutannot_clahe_{CONFIG.imsize[0]}_{fold}.tfrec\"\n",
    "        \n",
    "        if tpu_ok:\n",
    "            annot_train_dset = make_dataset(annot_train_paths) \n",
    "            annot_valid_dset = make_dataset(annot_valid_path)  \n",
    "        else:\n",
    "            annot_train_dset = make_dataset(annot_train_paths,cache_dir=\"kaggle_tf_cache\")\n",
    "            annot_valid_dset = make_dataset(annot_valid_path,cache_dir=\"kaggle_tf_cache\")\n",
    "\n",
    "        # Callbacks \n",
    "        ckp_path = f\"model_nb11_{CONFIG.version}_{fold}.h5\"\n",
    "        ckp = tf.keras.callbacks.ModelCheckpoint(ckp_path,save_best_only=True,monitor=\"val_loss\",mode=\"min\")\n",
    "        rlr = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\",patience=2,factor=0.5,min_lr=1e-6,mode=\"min\")\n",
    "        #rlr = tf.keras.callbacks.LearningRateScheduler(CosineAnnealing) \n",
    "        \n",
    "        # Training\n",
    "        # Teacher pred\n",
    "        print(\"Teacher Pred...\")\n",
    "        if DEBUG:\n",
    "            teacher_train_pred = tf.convert_to_tensor(np.zeros((annot_size[fold],11)),dtype=tf.float32)\n",
    "            teacher_valid_pred = tf.convert_to_tensor(np.zeros((9095-annot_size[fold],11)),dtype=tf.float32)\n",
    "        else:\n",
    "            teacher_model = create_teacher_model()\n",
    "            teacher_model.load_weights(f\"../input/ranzcrstageweight/model_nb10_3_{fold}.h5\")\n",
    "            steps = (annot_size[fold] + CONFIG.batchsize - 1)//CONFIG.batchsize \n",
    "            teacher_train_pred = teacher_model.predict(annot_train_dset,\n",
    "                                                       steps = steps, \n",
    "                                                       batch_size = CONFIG.batchsize,\n",
    "                                                       verbose = 1)[:annot_size[fold]]\n",
    "            steps = (9095 - annot_size[fold] + CONFIG.batchsize - 1)//CONFIG.batchsize \n",
    "            teacher_valid_pred = teacher_model.predict(annot_valid_dset,\n",
    "                                                       steps = steps,\n",
    "                                                       batch_size = CONFIG.batchsize,\n",
    "                                                       verbose = 1)[:9095-annot_size[fold]]\n",
    "        \n",
    "        train_dset = make_teacher_dataset(train_paths,teacher_train_pred,augment=True,repeat=True,shuffle=True)\n",
    "        valid_dset = make_teacher_dataset(valid_path,teacher_valid_pred) \n",
    "        \n",
    "        print(\"Student Training...\")\n",
    "        # Student\n",
    "        model = create_model()\n",
    "        steps_per_epoch = annot_size[fold]/CONFIG.batchsize\n",
    "        history = model.fit(train_dset,\n",
    "                            epochs=CONFIG.epochs,\n",
    "                            batch_size=CONFIG.batchsize,\n",
    "                            verbose=2 if DEBUG else 1, \n",
    "                            steps_per_epoch=steps_per_epoch,\n",
    "                            callbacks=[ckp,rlr],\n",
    "                            validation_data = valid_dset)\n",
    "        pd.DataFrame(history.history).to_csv(f\"history{CONFIG.version}_{fold}.csv\")\n",
    "        \n",
    "        print(\"Evaluate...\")\n",
    "        # Eval \n",
    "        model.load_weights(ckp_path) \n",
    "        valid_size = 9095 - annot_size[fold]\n",
    "        steps = (valid_size + CONFIG.batchsize - 1)//CONFIG.batchsize \n",
    "        pred = model.predict(valid_dset,\n",
    "                             steps = steps,\n",
    "                             batch_size=CONFIG.batchsize,\n",
    "                             verbose=1)[:valid_size]\n",
    "        valid_labels = df[df.fold == fold][labels].values\n",
    "        auc = mean_roc_auc(valid_labels,pred)\n",
    "        \n",
    "        print(f\"FOLD : AUC {auc}\")\n",
    "        scores.append(auc)\n",
    "        del train_dset,valid_dset,model,history,train_paths,valid_path\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-16T08:36:51.395345Z",
     "iopub.status.busy": "2021-03-16T08:36:51.394662Z",
     "iopub.status.idle": "2021-03-16T08:36:51.668634Z",
     "shell.execute_reply": "2021-03-16T08:36:51.669494Z"
    },
    "papermill": {
     "duration": 0.289739,
     "end_time": "2021-03-16T08:36:51.669732",
     "exception": false,
     "start_time": "2021-03-16T08:36:51.379993",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9095\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../input/ranzcr-sgkf-data/train_folds.csv\")\n",
    "annot = pd.read_csv(\"../input/ranzcr-clip-catheter-line-classification/train_annotations.csv\")\n",
    "annot_df = df[df['StudyInstanceUID'].isin(annot['StudyInstanceUID'].unique())].reset_index(drop=True)\n",
    "print(annot_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-16T08:36:51.694778Z",
     "iopub.status.busy": "2021-03-16T08:36:51.694188Z",
     "iopub.status.idle": "2021-03-16T08:36:51.696268Z",
     "shell.execute_reply": "2021-03-16T08:36:51.696732Z"
    },
    "papermill": {
     "duration": 0.016551,
     "end_time": "2021-03-16T08:36:51.696874",
     "exception": false,
     "start_time": "2021-03-16T08:36:51.680323",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "annot_size = [7232,7366,7226,7299,7257]\n",
    "#cv_tuner_from_tf(\"ranzcr512-sgkfannot\",\"ranzcr512withoutannotclahe\",annot_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-16T08:36:51.719951Z",
     "iopub.status.busy": "2021-03-16T08:36:51.719375Z",
     "iopub.status.idle": "2021-03-16T08:36:51.726300Z",
     "shell.execute_reply": "2021-03-16T08:36:51.726747Z"
    },
    "papermill": {
     "duration": 0.019754,
     "end_time": "2021-03-16T08:36:51.726887",
     "exception": false,
     "start_time": "2021-03-16T08:36:51.707133",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nteacher_pred = tf.convert_to_tensor(np.zeros((1863,11)),dtype=tf.float32)\\npaths = \"../input/ranzcr512-sgkfannot/train_annot_512_0.tfrec\"\\n\\ndef change_shape(img_label,teacher):\\n    img = img_label[0]\\n    label = img_label[1]\\n    return img,tf.concat((label,teacher),axis=0)\\n\\ndef make_teacher_dataset(paths,teacher_pred,cache_dir=False,augment=False,repeat=False,shuffle=0):\\n    dset = tf.data.TFRecordDataset(paths)\\n    teacher = tf.data.Dataset.from_tensor_slices(teacher_pred)\\n    dset = dset.map(read_labeled_tfrecord,num_parallel_calls=AUTO)\\n    dset = tf.data.Dataset.zip((dset,teacher))\\n    dset = dset.map(change_shape,num_parallel_calls=AUTO)\\n    \\n    dset = dset.map(augmenter,num_parallel_calls=AUTO) if augment else dset \\n    dset = dset.repeat() if repeat else dset\\n    dset = dset.shuffle(shuffle) if shuffle else dset \\n    dset = dset.batch(CONFIG.batchsize)\\n    dset = dset.prefetch(AUTO)\\n    return dset\\n\\ndset = make_teacher_dataset(paths,teacher_pred)\\nprint(dset)\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "teacher_pred = tf.convert_to_tensor(np.zeros((1863,11)),dtype=tf.float32)\n",
    "paths = \"../input/ranzcr512-sgkfannot/train_annot_512_0.tfrec\"\n",
    "\n",
    "def change_shape(img_label,teacher):\n",
    "    img = img_label[0]\n",
    "    label = img_label[1]\n",
    "    return img,tf.concat((label,teacher),axis=0)\n",
    "\n",
    "def make_teacher_dataset(paths,teacher_pred,cache_dir=False,augment=False,repeat=False,shuffle=0):\n",
    "    dset = tf.data.TFRecordDataset(paths)\n",
    "    teacher = tf.data.Dataset.from_tensor_slices(teacher_pred)\n",
    "    dset = dset.map(read_labeled_tfrecord,num_parallel_calls=AUTO)\n",
    "    dset = tf.data.Dataset.zip((dset,teacher))\n",
    "    dset = dset.map(change_shape,num_parallel_calls=AUTO)\n",
    "    \n",
    "    dset = dset.map(augmenter,num_parallel_calls=AUTO) if augment else dset \n",
    "    dset = dset.repeat() if repeat else dset\n",
    "    dset = dset.shuffle(shuffle) if shuffle else dset \n",
    "    dset = dset.batch(CONFIG.batchsize)\n",
    "    dset = dset.prefetch(AUTO)\n",
    "    return dset\n",
    "\n",
    "dset = make_teacher_dataset(paths,teacher_pred)\n",
    "print(dset)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-16T08:36:51.750599Z",
     "iopub.status.busy": "2021-03-16T08:36:51.749984Z",
     "iopub.status.idle": "2021-03-16T08:36:51.754434Z",
     "shell.execute_reply": "2021-03-16T08:36:51.754857Z"
    },
    "papermill": {
     "duration": 0.017694,
     "end_time": "2021-03-16T08:36:51.754990",
     "exception": false,
     "start_time": "2021-03-16T08:36:51.737296",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nx = np.abs(np.random.rand(100,22))\\ny = np.random.randint(0,2,(100,22))\\nlabel = tf.convert_to_tensor(y,dtype=tf.float32)\\npred = tf.convert_to_tensor(x,dtype=tf.float32)\\nprint(f\"LABEL {label}\\nPRED {pred}\")\\nprint(f\"LABEL SHAPE : {label.shape}\\nPRED SHAPE {pred.shape}\")\\nloss = CustomLoss(label,pred)\\nprint(f\"LOSS {loss}\")\\nauc = mean_roc_auc_(label,pred)\\nprint(f\"AUC {auc}\")\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "x = np.abs(np.random.rand(100,22))\n",
    "y = np.random.randint(0,2,(100,22))\n",
    "label = tf.convert_to_tensor(y,dtype=tf.float32)\n",
    "pred = tf.convert_to_tensor(x,dtype=tf.float32)\n",
    "print(f\"LABEL {label}\\nPRED {pred}\")\n",
    "print(f\"LABEL SHAPE : {label.shape}\\nPRED SHAPE {pred.shape}\")\n",
    "loss = CustomLoss(label,pred)\n",
    "print(f\"LOSS {loss}\")\n",
    "auc = mean_roc_auc_(label,pred)\n",
    "print(f\"AUC {auc}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-16T08:36:51.779992Z",
     "iopub.status.busy": "2021-03-16T08:36:51.779440Z",
     "iopub.status.idle": "2021-03-16T08:36:51.784215Z",
     "shell.execute_reply": "2021-03-16T08:36:51.784737Z"
    },
    "papermill": {
     "duration": 0.018896,
     "end_time": "2021-03-16T08:36:51.784879",
     "exception": false,
     "start_time": "2021-03-16T08:36:51.765983",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmodel = create_teacher_model()\\nmodel.load_weights(f\"../input/ranzcrstageweight/model_nb10_3_0.h5\")\\nfrom keras.utils import plot_model\\nplot_model(model)\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "model = create_teacher_model()\n",
    "model.load_weights(f\"../input/ranzcrstageweight/model_nb10_3_0.h5\")\n",
    "from keras.utils import plot_model\n",
    "plot_model(model)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.011651,
     "end_time": "2021-03-16T08:36:51.808412",
     "exception": false,
     "start_time": "2021-03-16T08:36:51.796761",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 14.967974,
   "end_time": "2021-03-16T08:36:52.930035",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-03-16T08:36:37.962061",
   "version": "2.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
